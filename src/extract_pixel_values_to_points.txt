
from time import time
import numpy as np
import pandas as pd
import geopandas as gpd
import h5py
import matplotlib as mpl
import matplotlib.pyplot as plt


class VIIRSImage:

    def __init__(self, ls_path):

        stime = time()
        print(f'Instantiating LandsatImage object for {ls_path}.')

        self.path = ls_path
        self.h5 = h5py.File(self.path)
        self.h5_array = np.array(self.h5['HDFEOS/GRIDS/VNP_Grid_DNB/Data Fields/DNB_BRDF-Corrected_NTL'])
        self.mandatory_qf_array = np.array(self.h5['HDFEOS/GRIDS/VNP_Grid_DNB/Data Fields/Mandatory_Quality_Flag'])
        self.qf_cloud_mask_array = np.array(self.h5['HDFEOS/GRIDS/VNP_Grid_DNB/Data Fields/QF_Cloud_Mask'])
        self.mask_array = None
        self.scaled_array = None
        self.filtered_array = None

        # Don't need to pad array like the Landsat images

        self.spin_up()

        print(f'LandsatImage object for {self.path} instantiated in {np.around(time() - stime, decimals=2)} seconds.')

    def spin_up(self):

        stime = time()
        print(f'Loading Quality Flag array...')
        # Already Qualtiy Flag arrays as attributes above, so really not loading anything
        print(f'Quality Flag array loaded in {np.around(time() - stime, decimals=2)} seconds.')
        print(f'Making mask from Quality Flags to filter array...')
        ctime = time()
        self.make_masks()
        print(f'Mask made in {np.around(time() - ctime, decimals=2)} seconds.')
        print(f'Applying Scale Factor and Additive Offset...')
        ctime = time()
        self.apply_factors_offsets_sr()
        print(f'Scale factors and additive offsets applied in {np.around(time() - ctime, decimals=2)} seconds.')
        print(f'Filtering array using mask...')
        ctime = time()
        #self.filtered_array = np.empty((self.tif.asarray().shape[0], self.tif.asarray().shape[1]))
        self.get_filtered_array()
        print(f'Array filtered using mask in {np.around(time() - ctime, decimals=2)} seconds.')

    def get_filtered_array(self):
        # np.where is like an if else statement np.where(<condition>, <if condition true>, <if condition false>)
        # Only going to look at the those places in mask array that are NaNs (i.e. not set to False by a Quality Flag)

        self.filtered_array = np.where(np.isnan(self.mask_array),
                                       self.scaled_array,
                                       np.nan)

        print(f"Filtered Array shape: {self.filtered_array.shape}")

    def apply_factors_offsets_sr(self):

        scale_factor = 0.1
        additive_offset = 0

        self.scaled_array = np.multiply(self.h5_array, scale_factor)

        return np.add(self.scaled_array, additive_offset)

    def make_masks(self):

        assert self.mandatory_qf_array.shape == self.qf_cloud_mask_array.shape

        gf_rows, gf_cols = self.mandatory_qf_array.shape

        self.mask_array = np.full((gf_rows, gf_cols), np.nan)

        it_mandatory_qf_array = np.nditer(self.mandatory_qf_array, flags=['multi_index'])

        it_qf_cloud_mask_array = np.nditer(self.qf_cloud_mask_array, flags=['multi_index'])

        it_h5_array = np.nditer(self.h5_array, flags=['multi_index'])

        for (qf_cloud_mask_value, qf_array_value, h5_array_value) in zip(it_qf_cloud_mask_array, it_mandatory_qf_array, it_h5_array):

            fill, poor_quality = unpack_mandatory_qf(qf_array_value)

            day, cloud, shadow, sea = qf_cloud_mask(qf_cloud_mask_value)

            missed_fill_value = True if h5_array_value == 65_535 else False

            pixel_index = it_mandatory_qf_array.multi_index

            if fill:
                self.mask_array[pixel_index] = True

            # This should catch any fill values not caught by the quality flag array
            if missed_fill_value:
                self.mask_array[pixel_index] = True

            if poor_quality:
                self.mask_array[pixel_index] = True

            if cloud:
                self.mask_array[pixel_index] = True

            if shadow:
                self.mask_array[pixel_index] = True

            if day:
                self.mask_array[pixel_index] = True

            if sea:
                self.mask_array[pixel_index] = True


def unpack_mandatory_qf(qf):

    fill = False
    if qf == 225:
        fill = True

    poor_quality = False
    if qf == 2 or qf == 3:
        poor_quality = True

    return fill, poor_quality


def qf_cloud_mask(qf):

    unpacked = bin(qf)[2:]

    while len(unpacked) < 16:
        unpacked = '0' + unpacked

    reversed = ''

    unpacked_list = list(unpacked)
    while unpacked_list:
        reversed += unpacked_list.pop()

    day = False
    if reversed[0] == '1':
        day = True

    cloud = False
    if reversed[9] == '1':
        cloud = True

    shadow = False
    if reversed[8] == '1':
        shadow = True

    # looking at bit 1-3, recall that python is not in-point inclusive
    sea = False
    if reversed[1:4] == "011":
        sea = True

    return day, cloud, shadow, sea


def get_diff_array(ls_one, ls_two):

    return np.subtract(ls_one.filtered_array,
                       ls_two.filtered_array,
                       where=~np.isnan(ls_one.filtered_array) & ~np.isnan(ls_two.filtered_array),
                       out=np.full((ls_one.filtered_array.shape[0],
                                    ls_one.filtered_array.shape[1]),
                                   np.nan))


def plot_image_main(ls_one):

    norm = mpl.colors.Normalize(vmin=0, vmax=1)
    cmap = mpl.colormaps["jet"]
    cmap.set_bad('k')
    my_cmap = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)

    fig = plt.figure(figsize=(12, 12), constrained_layout=True)

    ax = fig.add_subplot(1, 1, 1)

    ax.imshow(ls_one.filtered_array, cmap=my_cmap.cmap)

    plt.show()


def plot_images_diff_main(path_one, path_two):

    # Create LandsatImage objects
    ls_one = VIIRSImage(path_one)
    ls_two = VIIRSImage(path_two)

    # Get the difference between the arrays
    diff_arr = get_diff_array(ls_one, ls_two)

    norm = mpl.colors.Normalize(vmin=0, vmax=1)
    cmap = mpl.colormaps["jet"]
    cmap.set_bad('k')
    my_cmap = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)

    fig = plt.figure(figsize=(12, 12), constrained_layout=True)

    ax = fig.add_subplot(1, 3, 1)

    ax.imshow(ls_one.filtered_array, cmap=my_cmap.cmap)
    ax.set_title('Before')

    ax = fig.add_subplot(1, 3, 2)

    ax.imshow(ls_two.filtered_array, cmap=my_cmap.cmap)
    ax.set_title('After')

    norm = mpl.colors.Normalize(vmin=-1, vmax=1)
    cmap = mpl.colormaps["seismic"]
    cmap.set_bad('k')
    my_cmap = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)

    ax = fig.add_subplot(1, 3, 3)
    ax.set_title('Difference')

    ax.imshow(diff_arr, cmap=my_cmap.cmap)

    plt.show()


# Convert degrees and decimal minutes to decimal degrees
def dms_to_decdegs(degrees, dec_mins=0, dec_sec=0):
    # Return the decimal degrees
    return degrees + (dec_mins / 60) + (dec_sec / 3600)


# Get a VNP46 grid tile and pixel from a latitude (Coordinate object)
def get_tile_pixel_from_lat(coordinate, south_boundary=False):
    # Tiles run from 0-17 for +90 to -90 latitude
    # Tiles run from 0 - 43199 pixels
    tile_number = 18 - ((coordinate + 90) / 10)
    # If the tile number is right on a boundary
    if tile_number % 1 == 0:
        # If it's a South boundary
        if south_boundary is True:
            # Subtract 1 from the tile number
            tile_number -= 1
    # print(tile_number)
    # Get the pixel number
    pixel_number = (tile_number % 1) / (1 / 2400)
    # If the pixel number is right on a boundary
    if pixel_number % 1 == 0:
        # If it's a South boundary
        if south_boundary is True:
            # Subtract 1 from the pixel number
            pixel_number -= 1
            # If the pixel number is -1 (previous tile)
            if pixel_number == -1:
                # Change to 2399 (last in previous tile)
                pixel_number = 2399
    return int(np.floor(tile_number)), int(np.floor(pixel_number))


# Get a VNP46 grid tile and pixel from a longitude (Coordinate object)
def get_tile_pixel_from_long(coordinate, east_boundary=False):
    # Tiles run from 0-35 for -180 to +180 longitude
    tile_number = ((coordinate + 180) / 10)
    # If the tile number is right on a boundary
    if tile_number % 1 == 0:
        # If it's an East boundary
        if east_boundary is True:
            # Subtract 1 from the tile number
            tile_number -= 1
    # print(tile_number)
    # Get the pixel number
    pixel_number = (tile_number % 1) / (1 / 2400)
    # print(pixel_number)
    # If the pixel number is right on a boundary
    if pixel_number % 1 == 0:
        # If it's an East boundary
        if east_boundary is True:
            # Subtract 1 from the pixel number
            pixel_number -= 1
            # If the pixel number is -1 (previous tile)
            if pixel_number == -1:
                # Change to 2399 (last in previous tile)
                pixel_number = 2399
    return int(np.floor(tile_number)), int(np.floor(pixel_number))


class PointGeometry:

    # enter horizontal number as the first element and vertical number as the second element in the array tile

    def __init__(self, this_point_geometry, array, array_tile):

        self.point = (this_point_geometry.xy[0][0], this_point_geometry.xy[1][0])

        # print(self.point)

        self.point_tile = ()

        self.point_pixel = ()

        self.get_tiles_and_pixels()

        self.array_value_at_point = ()

        self.extract_pixel_values_to_points(array=array, array_tile=array_tile)

    def get_tiles_and_pixels(self):

        tile = [0, 0]

        pixel = [0, 0]

        # horizontal axis
        tile[0], pixel[0] = get_tile_pixel_from_long(self.point[0])

        # vertical axis
        tile[1], pixel[1] = get_tile_pixel_from_lat(self.point[1])

        self.point_tile = tuple(tile)

        self.point_pixel = tuple(pixel)

    def extract_pixel_values_to_points(self, array, array_tile):

        # y-coordinate [1] is the row index, x-coordinate [0] is the column index

        if array_tile == self.point_tile:

            self.array_value_at_point = array[self.point_pixel[1], self.point_pixel[0]]

        # Only want to get pixel values for points that are in the same tile the array is for
        elif array_tile != self.point_tile:

            self.array_value_at_point = np.nan

# (11, 7) are the horizontal and vertical tile numbers for the tile that Puerto Rico is inside of


def subset_point_gp_df_by_tile(point_gp_df_with_extractions, array_tile):

    return point_gp_df_with_extractions.loc[point_gp_df_with_extractions['point_tile'] == array_tile]


def extract_pixel_values_to_points(point_gp_df, array, array_tile=(11, 7)):

    geometry = gpd.GeoSeries(point_gp_df['geometry'])

    # Shapely geometry types: https://shapely.readthedocs.io/en/stable/geometry.html

    if sum(geometry.geometry.type == 'Point') != len(geometry.geometry.type == 'Point'):
        # Don't put in try-except block if you want the error to fail loudly
        raise ValueError('Not all feature geometries are Point geometries.')

    # List of crs attributes: https://pyproj4.github.io/pyproj/stable/api/crs/crs.html#pyproj.crs.CRS

    # NAD83 and WGS84 Respectively
    if str(geometry.crs) != "EPSG:4269" and str(geometry.crs) != "EPSG:4326":

        print(
            f"\nVector file has the following Projected Coordinate System or incompatible Geographic Coordinate System : \n{str(geometry.crs)}\n{str(geometry.crs.name)}\n")

        if "WGS" in str(geometry.crs.datum):

            print(
                "Extraction of image pixels will be done using the vector geometry's transformation to EPSG:4326 (WGS84) Geographic Coordinate System decimal degrees.\n")

            geometry = geometry.to_crs("EPSG:4326")

        elif "WGS" not in str(geometry.crs.datum):

            print(
                "Extraction of image pixels will be done using the vector geometry's transformation to EPSG:4269 (NAD83) Geographic Coordinate System decimal degrees.\n")

            geometry = geometry.to_crs("EPSG:4269")

    geometry_as_dict = geometry.to_dict()

    extractions = {
        "index": list(geometry_as_dict.keys()),
        "point_tile": [],
        "point_pixel": [],
        "array_value_at_pixel": []
    }

    for this_point in geometry_as_dict.values():

        this_point_geometry = PointGeometry(this_point_geometry=this_point, array=array, array_tile=array_tile)

        extractions["point_tile"].append(this_point_geometry.point_tile)

        extractions["point_pixel"].append(this_point_geometry.point_pixel)

        extractions["array_value_at_pixel"].append(this_point_geometry.array_value_at_point)

    assert len(extractions["index"]) == len(extractions["point_tile"]) == len(extractions["point_pixel"]) == len(extractions["array_value_at_pixel"]) == point_gp_df.shape[0]

    # Returns a new geopandas dataframe separate from the input one with the extractions merged in

    print("\nArray value extract to geometry complete.")

    return subset_point_gp_df_by_tile(
        point_gp_df_with_extractions=point_gp_df.reset_index().merge(
            pd.DataFrame(extractions),
            left_on='index',
            right_on='index',
            how="left"
        ),
        array_tile=array_tile
    )


if __name__ == '__main__':

    if True:

        test_file1 = '/Users/brevi/Documents/All_Files/2022_2024_Non_Harvard/Work_with_Ian_Paynter/LAADS_Tools/inputs/2017_09_19_to_2017_09_20_VNP46A2_5000_h11v07_pr_maria/VNP46A2.A2017262.h11v07.001.2020300190702.h5'

        test_file2 = '/Users/brevi/Documents/All_Files/2022_2024_Non_Harvard/Work_with_Ian_Paynter/LAADS_Tools/inputs/2017_09_19_to_2017_09_20_VNP46A2_5000_h11v07_pr_maria/VNP46A2.A2017263.h11v07.001.2021117133537.h5'

        # plot_images_diff_main(path_one=test_file1, path_two=test_file2)

        power_plants_filepath = '/Users/brevi/Documents/All_Files/Harvard_GSAS_RSI/Senior_Thesis/Data/Infrastructure/Electricity_Production/Power_Plants_US_2022/Power_Plants.shp'

        # Open power plants shapefile with geopandas
        pp_gdf = gpd.read_file(power_plants_filepath)

        test_viirs_image = VIIRSImage(test_file1)

        # plot_image_main(ls_one=test_viirs_image)

        pp_gdf_with_extractions = extract_pixel_values_to_points(point_gp_df=pp_gdf, array=test_viirs_image.filtered_array, array_tile=(11, 7))

        # Can't save geopandas file to shapefile b/c some dataframe elements are tuples or lists
        # Need to summarize these elements before writing to file or convert to pandas dataframe
        #   and save as pickle file
        #   pd.DataFrame(test_tl_gdf_with_extraction_df).to_pickle('./outputs/test_tl_gdf_with_extraction.pkl')

        # Saving Geopandas file
        # https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.to_file.html
        # test_tl_gdf_with_extraction_df.to_file('./outputs/test_tl_gdf_with_extraction.shp')
        # test_tl_gdf_with_extraction_df.to_file('./outputs/test_tl_gdf_with_extraction.json', driver="GeoJSON")

